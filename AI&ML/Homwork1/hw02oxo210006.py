# -*- coding: utf-8 -*-
"""hw02oxo210006.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U8qqf0VmLkNnG_7aLiIc1SdsVt-RpzRW
"""

################################################################################
#
# FILE:
# 	hw02_oxo210006.py
# AUTHOR:
# 	Olalekan Lawrence
#	oxo210006
# DESCRIPTION:
# 	Homework 2
# 	Python program removes noise from dataset, split on paragraph, then sentence,
#   extract date on each sentence, count word freq, sort and others...like check most
#   frequent words in the dataset
# DEPENDENCIES:
# 	Created with google collab
# 	dependencies, and/or Libraries used- re,datetime,datefinder,counter,nltk,tabulate and counter.
#
################################################################################


import re
import nltk

#uncomment to Install neccesary Libraries
#!pip install datefinder
#nltk.download('punkt')


# file path
file_path = "/content/text_news.txt"

# Read  file
with open(file_path, 'r', encoding='utf-8') as file:
    text = file.read()

# Remove symbols and noise
text = re.sub(r'@{2,}', '', text)  # Remove multiple @ symbols
text = re.sub(r'\b\d{5,8}\b', '', text)  # Remove digits with length 5 to 8
text = re.sub(r'\.{2,}', '.', text)  # Replace multiple periods with a single period
text = re.sub(r'\.\s+', '.', text)  # Remove extra spaces after periods
text = re.sub(r'\s+', ' ', text)  # Remove multiple spaces
text = re.sub(r'\s+\.', '.', text)  # Remove spaces before periods
text = re.sub(r'\.\s{2,}', ' ' , text)  # Remove two or more spaces after a period
text = re.sub(r'\s+([.,;?!"])', '', text)  # Remove spaces before punctuation
text = re.sub(r'"\s+', '"', text)  # Remove spaces after opening double quote
text = re.sub(r'\s+"', '"', text)  # Remove spaces before closing double quote
text = re.sub(r'@@', '', text)  # Remove digits
text = re.sub(r'@ @ @ @ @ @ @ @ @ @', '', text)  # Remove digits
text = re.sub(r'<h>', '', text)  # Remove <h> tags
text = re.sub(r'\b\d{6,9}\b', '', text)  # Remove digits with length 6 to 9
text = re.sub(r'\s+', ' ', text)  # Remove multiple spaces
text = re.sub(r'\.(?:,|\?|\.)', '', text)  # Remove periods followed by specific punctuation marks
text = re.sub(r'\.{2,}', '.', text)  # Replace multiple periods with a single period
text = re.sub(r'@@\d+', '', text)  # Remove occurrences of '@@' followed by one or more digits
text = re.sub(r'%', '', text)  # Remove the '%' symbol
text = re.sub(r'--', '', text)  # Remove occurrences of the '--' sequence
text = re.sub(r'\*', '', text)  # Remove the '*' symbol
text = re.sub(r'\.', '. ', text)  # Replace every period with a period followed by a space
text = re.sub(r"\s'(\w)", r"'\1", text)
text = re.sub(r'(\d{1,2}\.\d{2}\w{0,2})\. (\w)', r'\1. \2', text)
text = re.sub(r'\[\d+\]', '', text)  # Remove index-like patterns, e.g., [1], [2]

# Display a portion of the processed dataset

# Display a portion of the processed text for verification
print(text[:50000])

from nltk.tokenize import sent_tokenize
# Split on <p> for paragraphs
paragraphs = re.split(r'<p>', text)

# Tokenize each paragraph into sentences
sentences = []
for paragraph in paragraphs:
    # Tokenize the paragraph into sentences using nltk
    sentences.extend(sent_tokenize(paragraph))

# Display a portion of the sentences for verification
print(sentences[:10])  # Displaying the first 10 sentences

import re
import datefinder

text = re.sub(r'<.*?>', '', text)  # Remove HTML tags completely

# Date extraction
result = []

for i, sentence in enumerate(sentences):
    extracted_dates = []

    matches = datefinder.find_dates(sentence)
    for match in matches:
        date_str = str(match.date())

        # Additional checks to filter out potential false positives
        if len(date_str) > 4 and (re.search(r'\b\d{4}\b', date_str) or re.search(r'\b\d{2}\b', date_str)):
            extracted_dates.append(match.date())
        elif any(word in sentence.lower() for word in ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']):
            extracted_dates.append(match.date())
        elif any(month in sentence.lower() for month in ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']):
            extracted_dates.append(match.date())
        elif any(abbrev in sentence.lower() for abbrev in ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']):
            extracted_dates.append(match.date())

    if extracted_dates:
        result.append((sentence, extracted_dates))

# Display the result
for i, (sentence, date_list) in enumerate(result):
    print(f"---------------------------------------------------- SENTENCE: {i + 1:04d} ------------------------------------------------------")
    print(f'"{sentence}"')
    print(f"Extracted Dates: {[str(date) for date in date_list]}")

!pip install tabulate
from tabulate import tabulate

#Count Instances of Each Word
words = re.findall(r'\b\w+\b', text.lower())  # Extract words and convert to lowercase
word_count = {}
for word in words:
    if word in word_count:
        word_count[word] += 1
    else:
        word_count[word] = 1

#Sort the Dictionary by Frequency
sorted_word_count = dict(sorted(word_count.items(), key=lambda item: item[1], reverse=True))

total_words = len(words)

# Prepare data for tabulation
top_ten_data = []
for i, (word, count) in enumerate(sorted_word_count.items()):
    if i == 10:
        break

    #Exclude entries for punctuation
    if word.isalpha():
        frequency = count / total_words
        top_ten_data.append([word.lower(), count, f"{frequency:.5f}"])

# Display top ten entries in tabular form
headers = ["Word Token", "Word Count", "Word Frequency"]
print(tabulate(top_ten_data, headers=headers, tablefmt="grid"))
print("\n")

# Calculate and Display Top 20 Words
sorted_word_count_all = sorted(word_count.items(), key=lambda item: item[1], reverse=True)
top_twenty_data = []
for i, (word, count) in enumerate(sorted_word_count_all[:20]):
    frequency = count / total_words
    top_twenty_data.append([word, count, f"{frequency:.5f}"])

# Display top twenty entries in tabular form
headers_twenty = ["Word Form (Lexeme)", "Word Count", "Frequency"]
print(tabulate(top_twenty_data, headers=headers_twenty, tablefmt="grid"))
print("\n")